# -*- coding: utf-8 -*-
"""preprocess_ref.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l264VsioJpwyUTMGK_J--ymh0syWzjBw

importiamo le classiche librerie di python
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy import stats
from sklearn import metrics
import seaborn as sns

"""carico il txt già prelaborato in Pycharm, contiene in un unico file tutti i dati di ogni label"""

from google.colab import files
uploaded = files.upload()

file = open('ref_complete.txt')
lines = file.readlines()

"""Modifichiamo un po' il file. con line.split(',') si dividono le linee ogni volta che c'è una virgola (tipica separazione dei dati in csv). con line[4].split(';')[0] rimuoviamo la semicolonna dopo l'ultimo elemento dell'array. con last = last.strip() rimuoviamo ogni spazio extra. Facciamo anche un check degli errori."""

processedList = []

for i, line in enumerate(lines):
    try:
        line = line.split(',')
        last = line[5].split(';')[0]
        last = last.strip()
        if last == '':
            break;
        temp = [line[0], line[1], line[2], line[3], line[4], last]
        processedList.append(temp)
    except:
        print('Error at line number: ', i)

processedList[5]

"""creiamo un pandas dataframe e visualizziamo le prime righe"""

columns = ['quat1', 'quat2', 'quat3', 'quat4', 'user', 'activity']
df = pd.DataFrame(data = processedList, columns = columns)
df.head()
#df.dtypes

df.shape

df.info()

"""vediamo se i dati sono bilanciati"""

df_shape = df.shape
print("The data has Rows {}, Columns {}".format(df_shape[0], df_shape[1]))
sns.catplot(x="activity", kind="count", data=df, height=5, aspect=4, palette="Set3")

df['activity'].value_counts()

"""trasformiamo ogni valore di 'quat1', quat2, quat3, quat4 da string a float"""

df['quat1'] = df['quat1'].astype('float')
df['quat2'] = df['quat2'].astype('float')
df['quat3'] = df['quat3'].astype('float')
df['quat4'] = df['quat4'].astype('float')

df.info()

"""prendiamo l'attività con il numero più piccolo di campione e riduciamo tutte le altre al loro segmento iniziale con quel numero di campioni"""

#sitting_without_support = df[df['activity']=='sitting_without_support'].head(15863).copy()
#sitting_with_support = df[df['activity']=='sitting_with_support'].head(15863).copy()
#supine = df[df['activity']=='supine'].head(15863).copy()
#prone = df[df['activity']=='prone'].head(15863).copy()
#lying_left = df[df['activity']=='lying_left'].copy()
#lying_right = df[df['activity']=='lying_right'].head(15863).copy()
#standing = df[df['activity']=='standing'].head(15863).copy()
#stairs = df[df['activity']=='stairs'].head(15863).copy()
#walking = df[df['activity']=='walking'].head(15863).copy()
#running = df[df['activity']=='running'].head(15863).copy()
#cyclette = df[df['activity']=='cyclette'].head(15863).copy()

#balanced_data = pd.DataFrame()
#balanced_data = balanced_data.append([sitting_with_support, sitting_without_support, supine, prone, lying_left, lying_right, standing, stairs, walking, running, cyclette])
#balanced_data.shape

"""check se il dataset ora è bilanciato"""

#balanced_data['activity'].value_counts()

"""standardizziamo X per avere tutti i valori nello stesso range e visualizziamo i dati"""

y = df['activity']
X = df[['quat1', 'quat2', 'quat3', 'quat4']]
scaler = StandardScaler()
X = scaler.fit_transform(X)
dataset = pd.DataFrame(data = X, columns = ['quat1', 'quat2', 'quat3', 'quat4'])
dataset['activity'] = y.values

dataset.to_csv('preprocessref_complete.csv', index = False)