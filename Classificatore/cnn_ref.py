# -*- coding: utf-8 -*-
"""CNN_ref.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1peTlgO6oIXRj4Q6QDuB_Y6GuYB7ztklj
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from scipy import stats
from sklearn import metrics
import seaborn as sns
import io 
import os
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score

import itertools

import tensorflow as tf
from tensorflow import keras 
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from tensorflow.keras.layers import Conv2D, MaxPool2D
from tensorflow.keras.optimizers import Adam

from google.colab import files
uploaded = files.upload()

df = pd.read_csv(io.BytesIO(uploaded['preprocessrefreduced.txt'])) 

print(dataset)

dataset["activity"] = dataset["activity"].astype("|S")

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
dataset["activitynum"] = label_encoder.fit_transform(dataset["activity"])

dataset.head()

#replace_map = {'activity': {'cyclette': 0, 'lying_left': 1, 'lying_right': 2, 'prone': 3, 'running': 4, 'sitting_with_support': 5,
#      'sitting_without_support': 6, 'stairs': 7, 'standing': 8, 'supine': 9,
#      'walking_fast': 10, 'walkig_slow': 11}}
#df = dataset.copy()
#df.replace(replace_map, inplace=True)

N_TIME_STEPS = 200
N_FEATURES = 4
step = 20
segments = []
labels = []
for i in range(0, len(dataset) - N_TIME_STEPS, step):
    quat_1 = dataset['quat1'].values[i: i + N_TIME_STEPS]
    quat_2 = dataset['quat2'].values[i: i + N_TIME_STEPS]
    quat_3 = dataset['quat3'].values[i: i + N_TIME_STEPS]
    quat_4 = dataset['quat4'].values[i: i + N_TIME_STEPS]
    label = stats.mode(dataset['activitynum'][i: i + N_TIME_STEPS])[0][0]
    segments.append([quat_1, quat_2, quat_3, quat_4])
    labels.append(label)

"""modifichiamo segments in una forma migliore"""

segments = np.asarray(segments).reshape(-1, N_TIME_STEPS , N_FEATURES)
labels = np.asarray(labels)

X = segments
y = labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, 
                                                    random_state = 42, 
                                                    stratify = y)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

timesteps = len(X_train[0])
input_dim = len(X_train[0][0])
n_classes = 12
print("timesteps=", len(X_train[0]))
print("input_dim",len(X_train[0][0]) )

"""# 1DCNN"""

def create_model():
  model = tf.keras.models.Sequential([
    keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=X_train[0].shape),
    keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'),
    keras.layers.Dropout(0.6),
    keras.layers.MaxPooling1D(pool_size=2),
    keras.layers.Flatten(),
    keras.layers.Dense(50, activation='relu'),
    keras.layers.Dense(12, activation='softmax')])

  model.compile(loss='sparse_categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])
  return model

model = create_model()
model.summary()

import visualkeras

visualkeras.layered_view(model).show() # display using your system viewer
visualkeras.layered_view(model, to_file='output.png') # write to disk
visualkeras.layered_view(model, to_file='output.png').show() # write and show

visualkeras.layered_view(model)

model.compile(loss='sparse_categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])

checkpoint_path = "working/model_1D_{val_accuracy:.3f}.h5"

checkpoint_dir = os.path.dirname(checkpoint_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

early_stopping_callback = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy', patience=5)

model = create_model()

history = model.fit(X_train, y_train, 
          epochs=25, 
          batch_size=16,
          validation_data=(X_test, y_test), 
          verbose=1,
          callbacks=[cp_callback,
                     early_stopping_callback
                     ]
          )

validation_acc = np.amax(history.history['val_accuracy'])
print('Best validation accuracy:', validation_acc)

#!ls {checkpoint_dir}

from keras.models import load_model
test_model = load_model('working/model_1D_0.959.h5')

y_pred = test_model.predict(X_test, steps=1, verbose=0)

rounded_y_pred=np.argmax(y_pred, axis=-1)

print(classification_report(y_true=y_test, y_pred=rounded_y_pred))

cm = confusion_matrix(y_true=y_test, y_pred=rounded_y_pred)

print(cm)

labels = ['cyclette', 'lying_left', 'lying_right', 'prone', 'running',
          'sitting_with_support', 'sitting_without_support', 
          #'sitting',
          'stairs', 'standing', 'supine', 
          #'walking'
          'walking_fast', 'walkig_slow']

def print_confusionMatrix(y_test, rounded_y_pred):
  cm = confusion_matrix(y_test, rounded_y_pred)
 # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

plt.figure(figsize=(16,7))
sns.heatmap(cm, cmap = "Blues", annot = True, fmt = ".1f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()
    
print("-"*125)

precision = cm
#/cm.sum(axis = 0)
sns.set(font_scale=1.5)

plt.figure(figsize=(16,7))
sns.heatmap(precision, cmap = "Blues", annot = True, fmt = ".2f", xticklabels=labels, yticklabels=labels)
plt.title("Precision Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()
    
print("-"*125)

recall = (cm.T/cm.sum(axis = 1)).T

plt.figure(figsize=(16,7))
sns.heatmap(recall, cmap = "Blues", annot = True, fmt = ".2f", xticklabels=labels, yticklabels=labels)
plt.title("Recall Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()

def plot_learningCurve(history, epochs):
  # Plot training & validation accuracy values
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

  # Plot training & validation loss values
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

plot_learningCurve(history, 19)

"""Save and load entire model (serializing model)"""

model.save('mymodel.h5')

"""# 2DCNN

2DCNN funziona solo con dati tridimensionali
"""

print(X_train.shape)
print(X_test.shape)

X_train = X_train.reshape(18344, 200, 4, 1)
X_test = X_test.reshape(4586, 200, 4, 1)

training_data_count = len(X_train)
test_data_count = len(X_test) 
print(training_data_count)
print(test_data_count)

X_train.shape, X_test.shape

X_test[0].shape, X_train[1].shape

# Initiliazing the sequential model
model = Sequential()
# Configuring the parameters
model.add(Conv2D(11, (2, 2), activation = 'relu', input_shape = X_train[0].shape))
# Adding a dropout layer
model.add(Dropout(0.1)) 
model.add(Conv2D(32, (2, 2), activation='relu'))
# Adding a dropout layer
model.add(Dropout(0.2))
# Adding a flatten layer
model.add(Flatten())
model.add(Dense(64, activation = 'relu'))
# Adding a dropout layer
model.add(Dropout(0.5))
# Adding a dense output layer with softmax activation
model.add(Dense(12, activation='softmax'))

model.summary()

# Compiling the model
model.compile(optimizer='rmsprop', 
              loss = 'sparse_categorical_crossentropy', 
              metrics = ['accuracy'])

checkpoint_filepath = "working/model_2D_{val_accuracy:.3f}.h5"
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

early_stopping_callback = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy', patience=5)

# Training the model
history = model.fit(X_train, y_train,
                    epochs = 50, 
                    batch_size = 16,
                    validation_data= (X_test, y_test), 
                    shuffle=True,
                    callbacks=[model_checkpoint_callback,early_stopping_callback])

validation_acc = np.amax(history.history['val_accuracy'])
print('Best validation accuracy:', validation_acc)

from keras.models import load_model
test_model = load_model('working/model_2D_0.887.h5')

y_pred = test_model.predict(X_test, steps=1, verbose=0)

rounded_y_pred = np.argmax(y_pred, axis=-1)

print(classification_report(y_true=y_test, y_pred=rounded_y_pred))

labels = ['cyclette', 'lying_left', 'lying_right', 'prone', 'running',
          'sitting_with_support', 'sitting_without_support', 
          #'sitting',
          'stairs', 'standing', 'supine', 
          #'walking'
          'walking_fast', 'walkig_slow']

def print_confusionMatrix(y_test, rounded_y_pred):
  cm = confusion_matrix(y_test, rounded_y_pred)
#  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
precision = cm/cm.sum(axis = 0)
recall = (cm.T/cm.sum(axis = 1)).T
sns.set(font_scale=1.5)

plt.figure(figsize=(16,7))
sns.heatmap(cm, cmap = "Blues", annot = True, fmt = ".1f", xticklabels=labels, yticklabels=labels)
plt.title("Confusion Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()
    
print("-"*125)


plt.figure(figsize=(16,7))
sns.heatmap(precision, cmap = "Blues", annot = True, fmt = ".2f", xticklabels=labels, yticklabels=labels)
plt.title("Precision Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()
    
print("-"*125)

plt.figure(figsize=(16,7))
sns.heatmap(recall, cmap = "Blues", annot = True, fmt = ".2f", xticklabels=labels, yticklabels=labels)
plt.title("Recall Matrix", fontsize = 30)
plt.xlabel('Predicted Class', fontsize = 20)
plt.ylabel('Original Class', fontsize = 20)
plt.tick_params(labelsize = 15)
plt.xticks(rotation = 90)
plt.show()

def plot_learningCurve(history, epochs):
  # Plot training & validation accuracy values
  epoch_range = range(1, epochs+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

  # Plot training & validation loss values
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

plot_learningCurve(history, 11)